---
title: "Exploratory Data Analysis"
author: Matt Motoki
date: May 31, 2016
output: 
  html_document:
    fig_width: 10
    fig_height: 5
    toc: true
    toc_depth: 3
    highlight: tango
    theme: readable
    code_folding: hide
---
  
```{r setup, include=FALSE}
library(data.table)
library(grid)
library(plyr)
library(dplyr)
library(gridExtra)
library(stringr)
library(ggplot2)
gc(reset=TRUE) # garbage collection
setwd("C:/Users/Matt/Desktop/HIVET/Fundraising Analytics/R Markdown/")

```

# Preprocess the Data

## Load the Data
First we load our data into R.
```{r load and preprocess data}
filepath = "../Data Files/Subsetted Data/NonProfit/REL/"
# training dataset
train <- fread(paste0(filepath, "kaggle_training_dataset_formatted2.txt"), 
               stringsAsFactors = FALSE, drop = c("donated", "amount2", "databaseid"))

```

## Structure of the Data
Next, we take a quick look at the data.
```{r}
train$datemailed <- as.POSIXct(train$datemailed)

# calculate summary stats
trainSummary <- as.data.frame(do.call("rbind", lapply(names(train), function(col) {
  val <- train[[col]]
  val <- val[!is.na(val)]
  c(min(val), quantile(val, c(0.25,0.5,0.75)) , max(val), mean(val))
})))
names(trainSummary) <- c("Min", "25%", "50%", "75%", "Max", "Mean")


# extrac datemailed row and convert to datetime
row6 <- as.POSIXct(as.numeric(trainSummary[6,])- as.numeric(min(train$datemailed)),
           tz="HST", origin=min(train$datemailed))
row6 <- round(row6, units = "days")

# format columns
formatNum <- function(num) sprintf("%0.2f", num)
trainSummary$Mean <- formatNum(trainSummary$Mean)
trainSummary <- apply(trainSummary, 2, as.character)

# replace row 6
trainSummary[6,] <- as.character(row6)

# add row names
row.names(trainSummary) <- names(train)
trainSummary

```
Most of the variables are either ids or zipcodes and so the summary statistics (min, mean, max, etc.) are not meaningful.  Let's dive deeper into the analysis.  




# Calculating Net Profit
For a fundraising campaign to be successful, the total income from donations must exceed the total cost of sending out the fundraising packages; that is, the net profit should be positive and as large as possible.  The total income generated by donations is 
```{r}
sum(train$amount)
```
Assuming the cost of sending a package is 29 cents (which is the cost of a stamp in 2012), the baseline net profit that we will try to improve upon is
```{r}
sum(train$amount - 0.29)
```
Ideally, we would like to send packages only to prospects that will donate.  The optimal net profit is thus the total profit minus the cost of sending to the donors (and not non-donors) or
```{r}
with(train, sum(amount[amount>0] - 0.29))
```


# Donation Amount
The variable that we are ultimately trying to predict is the amount of a donation.  Let us try to gain more insight into this variable.

The average donation amount of an arbitrary package is
```{r}
mean(train$amount)
```
while the average donation amount among the packages that were successful is
```{r}
with(train, mean(amount[amount>0]))
```

The 10 most frequent donation amounts are
```{r}
top10Amount <- sort(table(train$amount), decreasing = TRUE)[1:10]
numAmounts <- as.numeric(names(top10Amount))
charAmounts <- paste0("$", names(top10Amount))
count = as.numeric(top10Amount)

count*numAmounts

formatDollar <- function(d) sprintf("$%0.2f",d)
formatPercent <- function(d) sprintf("%0.2f%%",d*100)
print(data.frame(Rank = 1:10,
                 Amount = charAmounts,
                 Count = count,
                 `Percent Total Amount` = formatPercent(count*numAmounts/sum(train$amount)),
                 `Percent Total Count` = formatPercent(count/nrow(train))
                 ),
      row.names=FALSE)
```
The large majority of prospects (947300) give nothing.  The most common non-zero donation amount is $25 (2917 prospects) followed by $10 (2717 prospects).  It also seems that most of the donations are under $100; in fact, the number of donations greater than $100 is
```{r}
sum(train$amount>100)
```
Thus, only 181 or about 0.02% of the prospects donate more than $100.  Next, let's view the number of positive donations less than or equal to $100
```{r}
keep <- with(train, amount>0 & amount <= 100)
freq <- table(round(train$amount[keep],2))

plot(freq/sum(freq)*100, xlim = c(0,100),
     xlab = "Donation Amount ($)",
     ylab = "Relative Frequency (%)",
     xaxs="i",yaxs="i", 
     main= "Relative Frequency of Donation Amounts")
grid(nx=20,ny=10)
``` 



## Average Success Rate
Recall that fundraising via mail tends to have a low success rate.  For this particular dataset, the overall success rate is
```{r}
mean(train$amount>0)*100
```
Let's see how success rate relates to a few of the other variables.  
```{r}
formatStr <- function(val, refVal) {
  paste0(sprintf("%0.2f, ", val), 
         str_pad(sprintf("(%0.0f%%)", val/refVal*100), 6, pad = " ") )
}


analyzeSuccess <- function(varname) {
  # extract data from training set
  refData <- subset(train, select = c(varname, "amount"))
  names(refData)[1] <- "variable"
  
  # summarize data
  summaryData <- refData %>% group_by(variable) %>% 
    summarize(` Did Not Donate` = sum(amount==0),
              ` Donated` = sum(amount>0),
              ` Success Rate`  = mean(amount>0)*100,
              ` Total Donation Amount` = sum(amount),
              ` Avg. Non-Zero Donation`  = mean(amount[amount>0]),
              ` Expected Donation`  = mean(amount>0)*mean(amount[amount>0])
    )
  names(summaryData)[1] <- varname
  
  # sort by expected donation
  refVals <- c(sum(train$amount))
  summaryData <- summaryData[order(` Expected Donation`, decreasing = TRUE),]
    
  refVals <- with(refData, list(sum(amount==0),
                                sum(amount>0),
                                mean(amount>0)*100,
                                sum(amount),
                                mean(amount[amount>0]),
                                mean(amount>0)*mean(amount[amount>0]))
  )
  names(refVals) <- names(summaryData)[-1] 

  # format variables
  for (stat in names(summaryData)[-1] ) {
    summaryData[[stat]] <- sapply(summaryData[[stat]], formatStr, refVals[[stat]])
  }
  
  # print results
  print(paste("The most/least important values of", varname, "are:"))  
  print(as.data.frame(summaryData))
  return(summaryData)
}

```


## Success Rate Versus Phase
First, let's see how success rate relates to the variable phase.
```{r}
analyzeSuccess("phase")
```
According to the results above, the mail sent during the phases 14, 6, and 3 can expect to get about 5 cents more than the average expected donation 41 cents.  Moreover, the success rate of these phases are all above average of 1.54%.


## Success Rate by ZIP codes
Now let's examine the zipcode variable in more detail.  The number of unique ZIP codes is
```{r}
length(unique(train$zip))
```
The distribution of Zip codes is
```{r}
hist(train$zip, 500, 
     xlab = "ZIP Code", main = "Histogram of 5-Digit ZIP Codes")
```
It seems like there is a sort of clustering of zipcodes.  This makes sense since ZIP codes are numbered with the first digit representing a certain group of U.S. states, the second and third digits together representing a region in that group (or perhaps a large city) and the fourth and fifth digits representing a group of delivery addresses within that region.  Hence, we can get aggregate ZIP code information by trunacting the last 2  digits of the ZIP code.
```{r}
train$zip3 <- round(train$zip/100)
```
The number of unique 3-digit ZIP codes is
```{r}
length(unique(train$zip1))
```
The distribution of the 3-digit ZIP codes is as follows
```{r}
hist(train$zip3, 500,
     xlab = "ZIP Code", main = "Histogram of 1-Digit ZIP Codes")
```
Although there are far fewer unique 3-digit ZIP codes compared to 5-digit ZIP codes, there are still too many ZIP codes to analyze using simple averages.  Instead, we can focus on 1-digit zipcodes (as an alternative, we can use *Association Rule Minning* which calculates--among other things--the confidence of the association between variables).
```{r}
length(unique(train$zip3))
train$zip1 <- floor(train$zip/10000)
hist(train$zip1, 50,
     xlab = "ZIP Code", main = "Histogram of 3-Digit ZIP Codes")
```

Let's see how the success rate and average donation amount is spread out over the aggregated ZIP codes.
```{r}
zip1Summary <- analyzeSuccess("zip1")
zip3Summary <- analyzeSuccess("zip3")
zipSummary <- analyzeSuccess("zip")
```
Accorrding to [wikipedia](https://en.wikipedia.org/wiki/List_of_ZIP_code_prefixes#Starts_with_5), the states with ZIP codes that start with 5 (that is, the states with the highest expected donation amount) are IA, WI, MN, SD, ND, MT. On the other hand, the states have a zip code that start with 8 (that is, the states with the lowest expected donation amounts) are CO, WY, UT, AZ, NM, NV.

```{r}
tab <- sort(table(train$zip), decreasing=TRUE)
for (z in as.numeric(names(tab[1:10]))) {
  with(train[train$zip==z], print( cbind(length(zip),  sum(amount), mean(amount>0))) )
}
```







